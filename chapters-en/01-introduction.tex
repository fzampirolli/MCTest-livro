
\mychapter{Introdução}\label{ch:introducao}

\section{Apresentação}

% contexto, lacuna, propósito, método, resultados e conclusão:

%Contexto:
%A avaliação dos estudantes é uma atividade crucial para o trabalho de um professor, pois permite avaliar de maneira justa e precisa o desempenho dos estudantes ao longo do curso, fornecendo \textit{feedback} importante para o seu desenvolvimento acadêmico. Além disso, a avaliação também é um meio importante para aprimorar a prática educativa, permitindo que os professores identifiquem pontos fortes e fracos de sua metodologia e aprimorem sua abordagem pedagógica para proporcionar um melhor aprendizado aos estudantes.

% JM - sugestão
A avaliação é uma prática essencial para todos os professores, pois fornece informações contínuas sobre o desenvolvimento e as dificuldades dos estudantes. Essas informações permitem que os professores identifiquem os pontos fortes e fracos de sua abordagem pedagógica, possibilitando ajustes ou a implementação de novas ações que apoiem o processo de aprendizagem dos estudantes.

% Lacuna:
Avaliar inúmeros estudantes individualizadamente é uma tarefa desafiadora para professores em todos os níveis de ensino, especialmente em disciplinas que exigem habilidades e competências específicas. Esse desafio é ainda maior em exames que envolvem Exercícios de Programação (EP), uma vez que exigem uma avaliação minuciosa dos processos de resolução de problemas, além da compreensão do código e da lógica utilizados pelos estudantes. Nesse sentido, é fundamental que os professores tenham acesso a ferramentas e técnicas que possam auxiliá-los nessa tarefa, como sistemas de avaliação automatizados e a utilização de exercícios parametrizados. A adoção dessas ferramentas permite uma avaliação mais eficiente das habilidades dos estudantes, garantindo que eles tenham a oportunidade de demonstrar seu conhecimento e habilidades adequadamente.

\subsection{Objetivo} 
Este livro visa disponibilizar uma solução abrangente e eficaz para a avaliação de estudantes. A abordagem colaborativa adotada permite que os professores reutilizem bancos de questões já utilizados por outros colegas que lecionam na mesma disciplina, economizando tempo e esforço na criação de avaliações personalizadas.

Essa metodologia pode ser aplicada tanto em provas unificadas em várias turmas com milhares de estudantes, quanto em disciplinas com turmas menores ministradas por um único professor.

\subsection{Método} 
Para ajudar professores a avaliar os estudantes, este livro apresenta o MCTest, um sistema de código aberto que permite a elaboração e correção de exames com questões de múltipla escolha ou dissertativas, incluindo EP. Esse sistema oferece questões parametrizadas e exames individualizados, que podem ser utilizados por várias turmas simultaneamente. O MCTest foi inicialmente desenvolvido para corrigir exames em processos seletivos para um curso de especialização na UFABC em 2012, mas evoluiu significativamente para uma versão inteiramente em Web.

Além disso, este livro ensina como criar EPs parametrizados para correção automática no Moodle, utilizando o \textit{plugin} VPL (\href{https://vpl.dis.ulpgc.es/}{\textit{Virtual Programming Lab}}), intercalando textos em LaTeX e códigos em Python. No entanto, antes de elaborar esses EPs, é importante discutir como navegar pelo sistema utilizando um dos seus três tipos de usuários: administrador, coordenador de disciplina e professor. Mesmo um professor sem habilidade de programação pode utilizar o MCTest para criar exames com questões estáticas, onde a única variação é o sorteio das questões e das alternativas. Cada tipo de usuário possui um conjunto de funcionalidades para criar e alterar as diversas entidades do sistema, incluindo Instituto, Curso, Disciplina, Tópico, Questão, Turma, Professor, Estudante e Exame.

O MCTest já foi implantado com sucesso na UFABC e serve como plataforma para os professores e gestores da instituição. O leitor pode examinar a implantação deste sistema em \href{http://mctest.ufabc.edu.br}{mctest.ufabc.edu.br} para entender melhor como o sistema funciona e como pode ser utilizado para aprimorar a avaliação de habilidades dos estudantes.

\subsection{Resultados} 
O livro apresenta os resultados de dezenas de experimentos realizados ao longo dos últimos 10 anos em disciplinas na UFABC. Os experimentos foram realizados em disciplinas como Bases Computacionais da Ciência, Processamento da Informação, Programação Estruturada, Processamento Digital de Imagens e Visão Computacional, tanto nos Bacharelados em Ciência e Tecnologia (BCT) e Ciência da Computação (BCC), quanto na pós-graduação em Ciência da Computação. Além disso, o livro também relata um experimento realizado na disciplina de Funções de Uma Variável (Cálculo) no BCT, utilizando a biblioteca \href{http://sympy.org}{sympy.org} para questões algébricas.

Este livro apresenta os resultados de experimentos conduzidos em três modalidades: híbrida, totalmente remota e totalmente presencial. Foram selecionados os melhores resultados obtidos por meio de artigos e registros de software, os quais estão disponíveis para consulta em \href{http://vision.ufabc.edu.br}{vision.ufabc.edu.br}. Os experimentos demonstram a eficácia do método avaliativo utilizando o MCTest na avaliação de disciplinas de computação, bem como em processos seletivos gerais.

% Conclusão:
Com o sistema MCTest apresentado neste livro, os professores têm à disposição uma ferramenta poderosa para aprimorar a avaliação de habilidades e competências dos estudantes em programação. Ao utilizar o MCTest, os professores podem minimizar o esforço de criar e corrigir exames e EPs, permitindo que se dediquem a atividades de ensino menos repetitivas e mais significativas.

Além disso, o MCTest oferece uma avaliação mais justa e eficiente, tornando o processo de avaliação menos suscetível a erros humanos e mais preciso. Isso pode proporcionar uma experiência de aprendizado mais satisfatória para os estudantes, que se sentirão mais seguros e motivados a progredir em suas habilidades.
 
% \noindent
% \textbf{Palavras-chave:} Avaliação automatizada, Avaliação parametrizada, Ensino de Programação, MOOC.

\begin{mybox}{corObs}{\textbf{Observação:\\\vspace{-3mm}\hrule\vspace{3mm}}}
Os textos apresentados neste livro foram adaptados de conversas com modelos de inteligência artificial (IA) disponíveis em \href{https://poe.com/}{poe.com}. 
\\\\
Por exemplo, os próximos três parágrafos em itálico constituem uma resposta gerada pela IA em resposta a uma solicitação específica para expandir o parágrafo anterior. Essa solicitação foi feita após várias consultas em diferentes partes dos Capítulos \ref{ch:introducao} -- \nameref{ch:introducao} e \ref{ch:visaoGeral} -- \nameref{ch:visaoGeral} deste livro. É importante ressaltar que a resposta fornecida por \textit{chatbot} não pode ser considerada uma conversa real, pois apenas responde a uma solicitação e não faz perguntas adicionais para aprofundar a compreensão do contexto. Portanto, trata-se de uma resposta específica a uma solicitação, e não de uma conversa propriamente dita.

\end{mybox}

\begin{mybox}{corCopia}{\textbf{Resposta de \href{https://poe.com/ChatGPT}{poe.com/ChatGPT}:\\\vspace{-3mm}\hrule\vspace{3mm}}}

{\em\color{black}
Poe.com é um site que oferece acesso a vários modelos de inteligência artificial para conversação, incluindo chatbots e modelos de linguagem, por meio de uma interface amigável ao usuário. Os usuários podem inserir textos de entrada e receber respostas geradas pelos modelos de IA, treinados em grandes conjuntos de dados de linguagem humana.
\\\\
Os textos apresentados neste livro foram adaptados de conversas com esses modelos de IA, usando as respostas geradas pelos modelos como ponto de partida para uma edição e refinamento adicionais por autores humanos. O objetivo foi criar conteúdo informativo e envolvente que aproveite as capacidades dos modelos de IA, ao mesmo tempo, em que incorpora a criatividade e a expertise dos autores humanos.
\\\\
Ao utilizar modelos de IA dessa maneira, esperamos demonstrar o potencial dessas tecnologias para aprimorar o processo de criação de conteúdo e fornecer novas oportunidades de colaboração entre autores humanos e máquinas inteligentes.}
\end{mybox}

\section{Motivações em ler este livro}

{\color{red} Melhorar esta seção, por ser copiado integramente da IA!}

Há várias motivações para um professor ler um livro sobre geração e correção automática de provas:

\begin{description}
\item[Economia de tempo:] A geração automática de provas pode economizar muito tempo para o professor, já que ele não precisa criar cada prova manualmente. Além disso, a correção automática de provas também economiza tempo, pois o professor não precisa passar horas corrigindo cada prova individualmente.

% \item[Personalização:] A geração automática de provas também pode permitir a personalização das provas para cada estudante. Com base nas habilidades e no nível de conhecimento de cada estudante, as provas podem ser geradas automaticamente para atender às necessidades individuais de cada estudante.

\item[Padronização:] A geração automática de provas também pode garantir que as provas sejam padronizadas e justas, pois elas podem ser geradas automaticamente com a mesma dificuldade e formato para todos os estudantes.

\item[\textit{feedback} imediato:] A correção automática de provas permite que os estudantes recebam \textit{feedback} imediato sobre seu desempenho, o que pode ajudá-los a identificar áreas em que precisam melhorar e a se preparar melhor para futuras avaliações.

\item[Efetividade:] A geração automática de provas pode ajudar a aumentar a efetividade do processo de ensino e aprendizagem, pois permite que os professores se concentrem em outras áreas do ensino, como planejamento de aulas e atividades de sala de aula.
\end{description}

Em resumo, um livro sobre geração e correção automática de provas pode fornecer informações valiosas para professores que desejam aprimorar o processo de avaliação em suas salas de aula e economizar tempo valioso. Além disso, a tecnologia de geração e correção automática de provas está em constante evolução, e um livro atualizado pode fornecer aos professores as informações mais recentes sobre as melhores práticas e tecnologias disponíveis.

\section{Melhores práticas para preparar um exame}

{\color{red} Melhorar esta seção, por ser copiado integramente da IA!}

Algumas das melhores práticas para gerar e corrigir exames são:

\begin{description}

\item[Criar um plano de prova claro e detalhado:] Antes de gerar uma prova, é importante ter uma compreensão clara dos objetivos de aprendizagem e do conteúdo que será abordado. Um plano de prova delineia o conteúdo e as habilidades que serão avaliados, os tipos de perguntas que serão usadas e o peso ou valor de cada pergunta.

\item[Usar uma variedade de tipos de perguntas:] Uma boa prova deve incluir uma mistura de diferentes tipos de perguntas, como múltipla escolha, resposta curta, ensaio e perguntas de resolução de problemas. Isso ajuda a avaliar diferentes tipos de conhecimento e habilidades e garante que a prova não esteja enviesada para um tipo específico de pergunta.

\item [Certificar-se de que as perguntas sejam válidas e confiáveis:] \ Cada pergunta deve ser cuidadosamente construída para garantir que ela seja válida e confiável. Validade refere-se a pergunta mede o que se pretende medir, enquanto confiabilidade se refere à consistência dos resultados obtidos a partir da pergunta.

% \item [Personalizar as provas para atender às necessidades individuais:] \ Personalizar as provas pode ajudar a garantir que os estudantes sejam avaliados em suas forças e fraquezas individuais. Isso pode ser alcançado gerando diferentes versões da mesma prova que são adaptadas ao nível de conhecimento e habilidades de cada estudante.

\item [Automatizar o processo de correção:] A correção automatizada pode economizar tempo e garantir consistência na correção. Isso pode ser alcançado por meio do uso de softwares ou plataformas online que podem corrigir automaticamente perguntas de múltipla escolha e resposta curta.

\item [Fornecer \textit{feedback} aos estudantes:] O \textit{feedback} é uma parte importante do processo de aprendizagem e pode ajudar os estudantes a identificar áreas em que precisam melhorar. Fornecer \textit{feedback} pode ser feito manualmente pelo professor ou por meio de sistemas automatizados que fornecem \textit{feedback} imediato aos estudantes.
\end{description}

Analisar os resultados da prova: A análise dos resultados da prova pode fornecer informações valiosas sobre o desempenho dos estudantes e pode ajudar a identificar áreas em que os estudantes precisam de suporte adicional. Os resultados da prova também podem ser usados para avaliar a eficácia dos métodos de ensino e para melhorar as avaliações futuras.

Em geral, as melhores práticas para gerar e corrigir provas envolvem planejamento cuidadoso, atenção aos detalhes e foco na avaliação da aprendizagem dos estudantes de maneira justa e eficaz.

Aqui estão algumas referências científicas recentes e muito relevantes para melhores práticas para realizar provas com correção automática:

\begin{itemize}
\item \textbf{``Automated Feedback in Mathematics Education: A Systematic Review'' por Marieke van der Schaaf, et al. (2020):} Este estudo revisa a literatura sobre o uso de \textit{feedback} automatizado em educação matemática e discute as melhores práticas para implementar esse tipo de \textit{feedback}.

\item \textbf{``Automated Item Generation in Assessments: A Systematic Review'' por Nienke M. Moolenaar, et al. (2019):} Este estudo revisa a literatura sobre a geração automática de itens de teste e discute as vantagens e desvantagens desse método de geração de itens.

\item \textbf{``Using Automated Scoring to Assess Students' Writing Skills: Opportunities and Challenges'' por Daniel F. McCaffrey, et al. (2020):} Este artigo discute as oportunidades e desafios do uso de pontuação automática para avaliar as habilidades de escrita dos estudantes.

\item \textbf{``Automated Multiple-Choice Test Generation: A Review'' por Qinghua Zheng, et al. (2019):} Este estudo revisa a literatura sobre a geração automática de testes de múltipla escolha e discute as melhores práticas para implementar esse método de geração de testes.

\item \textbf{``Automated Essay Scoring in Educational Assessment: An  Application of Natural Language Processing and Machine Learning'' por Xitao Fan e Michael T. Kane (2019):} Este artigo discute o uso de processamento de linguagem natural e aprendizado de máquina para pontuação automática de ensaios em avaliações educacionais.
\end{itemize}

\section{Breve histórico do MCTest}\label{sec:historico}

Nesta seção, apresentaremos um breve histórico do MCTest. Essa ferramenta surgiu como uma resposta à necessidade do curso de Especialização em Tecnologias e Sistemas de Informação (TSI) Latu-Sensu da UFABC, que foi o primeiro oferecido pela universidade em 2010 (TSI-1). Desde então, o MCTest tem sido amplamente utilizado em diversos processos seletivos e exames de disciplinas, além de ser uma ferramenta importante na Escola Preparatória da UFABC.

Ao longo deste livro, descreveremos os experimentos realizados com o MCTest em detalhes, abrangendo diversos aspectos de seu uso e aplicação. Se você deseja saber mais sobre o uso do MCTest em processos seletivos, exames de disciplinas ou na Escola Preparatória da UFABC, basta consultar os capítulos específicos dedicados a esses temas.

\subsection{MCTest no TSI}

O curso TSI-1 estabeleceu uma parceria com o programa Universidade Aberta do Brasil, vinculado ao Ministério da Educação (UAB/MEC), e oferecido na modalidade de ensino a distância (EaD), com provas presenciais correspondendo a mais de 50\% da nota de aprovação do estudante. Em 2010, houve 1078 candidatos para as 200 vagas disponíveis em quatro polos do estado de São Paulo, com 16 tutores no total. 

A segunda edição do curso (TSI-2) iniciou em 2012, com 1171 inscritos distribuídos em 4 polos, com 50 estudantes em cada polo. No entanto, apenas 674 candidatos concluíram o processo seletivo \cite{2013:Zampirolli.Quilici-Gonzalez.ea}. 

Na terceira oferta, em 2014 (TSI-3), foram 689 candidatos, para 6 polos, com 300 estudantes matriculados. Foram 11 tutores no início, porém, na fase do TCC, em 2015, foram 16 tutores no total. 

A quarta edição do curso (TSI-4) ocorreu em 2017, porém sem as bolsas UAB para professores e tutores. Como resultado, foram oferecidas apenas duas turmas, nos polos da UFABC em Santo André (SA) e São Bernardo do Campo (SBC), com 25 estudantes em cada polo e sem a presença de tutores. Apesar disso, a demanda permaneceu alta, com 863 inscritos para apenas 50 vagas disponíveis nessa edição.

Até a quarta edição do TSI, a parte administrativa do curso era conduzida pela Pró-Reitoria de Extensão. Durante a fase de transição dos cursos de especialização para a Pró-Reitoria de Pós-Graduação, houve um intervalo maior entre as edições do curso, que foi agravado pela pandemia de COVID-19. Como resultado, somente no segundo semestre de 2022 foi possível iniciar o TSI-5, também sem as bolsas UAB, com apenas 25 estudantes em cada polo da UFABC em SA e SBC. Nessa edição, talvez devido à pandemia, apenas 63 candidatos participaram do processo seletivo, em contraste com a edição anterior, que teve uma média de 17,26 candidatos por vaga.

No início de 2023, iniciamos a sexta edição do TSI (TSI-6), agora com o retorno das bolsas UAB. Essa edição está sendo conduzida em paralelo com a TSI-5, e conta com 7 tutores. %No entanto, agora existe apenas um coordenador geral de tutores para todas as especializações da UFABC. 
Foram registrados 565 candidatos para os 6 polos do estado de São Paulo, com uma média de 35 estudantes por polo.

\subsection{Versões do MCTest}\label{sec:registrosSoftware}

O MCTest é um projeto que evoluiu ao longo do tempo, e isso pode ser visto nas diferentes versões registradas no Instituto Nacional de Propriedade Intelectual (INPI). Cada versão registra uma evolução do projeto em termos de tecnologia, metodologia e objetivos.

A primeira versão do MCTest (MCTest-1) foi registrada no INPI com o número de registro BR 51 2013 001231 7. Essa versão foi desenvolvida em Matlab para permitir a correção automática dos exames gerados em Word ou BROffice. Essa versão do MCTest-1 foi utilizada nos processos seletivos do TSI até 2017, contribuindo significativamente para a avaliação das competências cognitivas dos candidatos.

Desenvolvemos uma versão do MCTest chamada MCTest-2 em colaboração com um estudante de Iniciação Científica, registrada no INPI com o número de registro BR 51 2015 001444 7. Essa versão, disponível para dispositivos Android, permitia a correção automática dos exames gerados em Word ou BROffice \cite{2014:China.Zampirolli,2015:Zampirolli.China.ea,2016:China.Zampirolli.ea}. 

A versão MCTest-3 foi desenvolvida em Python e registrada no INPI com o número de registro BR 51 2015 001445 5. Assim como as versões anteriores, essa versão também permitia a correção automática de exames gerados em Word/BROffice.

Já a versão MCTest-4, registrada no INPI com o número de registro BR 51 2016 001344 3, foi desenvolvida em Python e também permitia a correção automática dos exames. No entanto, os exames foram digitalizados e enviados por FTP para o servidor \href{http://vision.ufabc.edu.br}{vision.ufabc.edu.br}, com os exames gerados pela versão  versão MCTest-4.G \cite{2016:Zampirolli.Batista.ea}. Essa versão representou um avanço significativo em relação às anteriores, ao permitir o envio remoto dos exames digitalizados e a correção automática, simplificando o processo de avaliação  dos candidatos.

A versão MCTest-4.G, registrada no INPI com o número de registro BR 51 2018 001202 7, introduziu uma mudança significativa no processo de geração dos exames, que agora são criados em \LaTeX{} e disponibilizado em  \href{https://github.com/fzampirolli/mctest4}{github.com/fzampirolli/mctest4} \cite{2016:Zampirolli.Batista.ea}.

Posteriormente, entre maio e agosto de 2018, foi desenvolvida e lançada a versão atual do MCTest, a MCTest-5.2. Essa versão apresentou grandes mudanças, sendo disponibilizada em páginas web e desenvolvida em Python com IDE Django, permitindo a geração e correção automática de exames. A MCTest-5.2 está disponível em  \href{https://github.com/fzampirolli/mctest}{github.com/fzampirolli/mctest}, com os exames gerados em \LaTeX \ e usando o banco de dados MySQL. Desde o seu lançamento, essa nova versão gerou diversas publicações, a partir de 2018, que podem ser acessadas através do site \href{http://vision.ufabc.edu.br}{vision.ufabc.edu.br}. 

A grande contribuição do MCTest ao estado da arte em exames avaliativos e formativos está na possibilidade de criar questões parametrizadas, intercalando descrições em \LaTeX \ com códigos em Python, disponível a partir da versão MCTest-4.G. Os exames gerados com essas questões podem ter a correção automática com: 

\begin{enumerate}
    \item Provas digitalizadas e enviadas para o MCTest; 
    \item Se forem questões de Exercícios de Programação (EP), com respostas dadas em código em alguma linguagem de programação, o MCTest gera um arquivo com os casos de teste e outro com a variação de cada estudante. Esses arquivos devem ser inseridos em atividades VPL no Moodle para a correção automática; 
    \item Outra possibilidade é o MCTest exportar um banco de questões em formato AIKEN ou XML, que podem ser importados pelo Moodle para criar exames. 
\end{enumerate}

O Moodle também aceita questões paramétricas, mas são limitadas ao conjunto de funções do PHP, como relatado no artigo \cite{2021:Zampirolli.Batista.ea*1}.

\subsection{MCTest nos processos seletivos e exames de disciplinas}

Desde 2012, todos os processos seletivos do TSI têm sido realizados com o uso do MCTest. Até a versão MCTest-4, os exames eram criados em editores de texto, como Word ou BROffice. A partir da versão MCTest-4G, no entanto, os exames começaram a ser criados diretamente pelo sistema.

Além disso, os professores da disciplina de Processamento de Informação do Bacharelado em Ciência e Tecnologia da UFABC, na modalidade semipresencial, viram a oportunidade de utilizar o sistema em questões contendo Exercícios de Programação, como relatado no artigo de \citeonline{2018:Zampirolli.Goya.ea}. Com o passar do tempo, várias outras turmas e professores também começaram a utilizar o sistema e a sugerir melhorias.

Desde 2012, todas as 13 disciplinas do TSI tiveram seus exames presenciais corrigidos com o auxílio do MCTest. A partir de 2017, os exames também passaram a ser gerados pelo sistema sendo reaproveitados em cada nova oferta, com pequenas modificações. Essa mudança representou uma significativa melhoria na eficiência e rapidez do processo de avaliação, além de permitir a personalização e adaptação dos exames para cada nova oferta.

\subsection{MCTest na Escola Preparatória}

A UFABC oferece gratuitamente à comunidade da região do ABC um curso preparatório para vestibulares chamado Escola Preparatória da UFABC (EDUFABC). Desde 2017, o MCTest tem sido um importante aliado no processo seletivo dos candidatos da EDUFABC. Esses processos atraem milhares de candidatos para as cerca de 300 vagas disponíveis anualmente.

Para viabilizar esse processo, utilizamos o MCTest para gerar o quadro de respostas dos candidatos, enquanto as questões são impressas separadamente. O uso do MCTest tem sido fundamental para agilizar e simplificar o processo seletivo, permitindo a correção automática das provas e a geração rápida do resultado. Além disso, a precisão e confiabilidade do sistema garantem uma avaliação justa e imparcial dos candidatos, contribuindo para a excelência acadêmica da UFABC e para o sucesso dos estudantes que frequentam a EDUFABC.

\subsubsection{ENEM Interativo}

Em parceria com a EDUFABC, desenvolvemos um sistema interativo para os estudantes poderem estudar utilizando provas antigas do ENEM e os microdados disponibilizados pelo INEP, chamado \href{http://mctest.ufabc.edu.br:8000/ENEM}{ENEM interativo}. Nesse sistema, as provas em PDF são convertidas em HTML e incluímos botões de resposta para cada questão. Ao final de cada exame, o botão de estatísticas abre uma nova página com dados do gabarito, respostas dos estudantes, habilidade (valor disponibilizado pelo INEP) e gráficos.

Esses gráficos mostram a Curva Característica do Item (CCI) da Teoria de Resposta ao Item (TRI) \cite{birnbaum1968some}, sendo calculada a partir dos parâmetros da amostra aleatória de 10.000 estudantes, incluindo a discriminação (a), habilidade (b) e chute (c). Os valores médios e o desvio padrão (std) da amostra também são calculados, permitindo uma melhor compreensão da distribuição dos resultados.

Outro gráfico gerado é o BoxPlot \cite{jw1977exploratory}, juntamente com o ViolinPlot \cite{hintze1998violin}, para visualizar as frequências de acertos (1) e erros (0) de forma mais clara e precisa.

É importante ressaltar que esses gráficos estão disponíveis apenas para exames com respostas de mais de 10.000 estudantes. Essa ferramenta tem sido uma contribuição para o processo de preparação dos estudantes para o ENEM, fornecendo informações valiosas sobre o desempenho dos estudantes e as tendências de cada questão ao longo do tempo \cite{2021:Zampirolli.Junior.ea}.

\subsubsection{Comparações de três métodos de seleção}

Realizamos um estudo comparativo entre três métodos de seleção de candidatos para a EDUFABC: 1) o uso do MCTest com exames presenciais, com a aplicação da Teoria Clássica do Item (TCI); 2) o uso do Moodle durante a pandemia de COVID-19, realizado a distância com a TCI; e 3) o uso do MCTest com exames presenciais e a Teoria de Resposta ao Item (TRI). Concluímos que, ao utilizar a TRI, as chances de empate entre candidatos são consideravelmente menores. Além disso, constatamos que a correlação entre as classificações obtidas pelos métodos TCI e TRI é alta, o que demonstra coerência entre os dois métodos de pontuação. \cite{2021:Zampirolli.Batista.ea}.



\section{Direitos autorais}

Nesta seção, abordamos os direitos autorais do software e das  questões criadas pelos professores e disponibilizadas no banco de dados do MCTest.

\subsection{Direitos autorais do software}

Até a primeira edição deste livro, o MCTest foi desenvolvido integralmente pelo Prof. Francisco de Assis Zampirolli, da Universidade Federal do ABC (UFABC), visando atender às demandas da instituição na avaliação de inúmeros estudantes e candidatos. O sistema contou com a valiosa colaboração de colegas da UFABC, que compartilharam suas necessidades em relação às avaliações. No entanto, é crucial ressaltar que o MCTest não é um produto comercial e, infelizmente, não segue rigorosamente o ciclo de vida de desenvolvimento de software.

Trata-se de um sistema construído inspirado no modelo de prototipagem. Para vir a se tornar um produto comercial, seria necessário submetê-lo a uma engenharia reversa e aprimorá-lo, sobretudo no que concerne à navegabilidade entre as telas e à adição de mais funcionalidades de gestão de processos. 

Mesmo com as limitações mencionadas anteriormente, o MCTest está em produção na UFABC e é utilizado por professores e gestores para avaliar milhares de estudantes e candidatos, reduzindo significativamente a parte repetitiva dos processos de avaliação.

O MCTest possui código aberto e está disponível no \href{https://github.com/fzampirolli/mctest}{GitHub}, podendo ser usado e modificado sob a licença AGNU. Isso implica que todos têm a liberdade de utilizar o sistema. Para manter o MCTest atualizado, melhorias feitas por terceiros e implementadas em seus servidores também devem ser compartilhadas com o público. Essa licença pode ser encontrada na implantação na UFABC em \href{http://mctest.ufabc.edu.br/license}{mctest.ufabc.edu.br/license} e está apresentada a seguir:

\begin{mybox}{corCopia}{\textbf{Licença:\\\vspace{-3mm}\hrule\vspace{3mm}}}
{\em Copyright (C) 2018-2023 Francisco de Assis Zampirolli from Federal University of ABC and individual contributors. All rights reserved.
This file is part of MCTest 5.2.
Languages: Python, Django, and many libraries described at
\href{https://github.com/fzampirolli/mctest}{github.com/fzampirolli/mctest}.
\\\\
You should cite some references included in \href{http://vision.ufabc.edu.br}{vision.ufabc.edu.br} in any publication about it.
\\\\
MCTest is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License (\href{http://gnu.org/licenses/agpl-3.0.txt}{gnu.org/licenses/agpl-3.0.txt}) as published by the Free Software Foundation, either version 3 of the License or (at your option) any later version.
\\\\
MCTest is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.}
\end{mybox}

\subsection{Direitos autorais das questões disponíveis no BD}\label{sec:deAcordo}

Outro ponto muito importante a respeito dos direitos autorais refere-se às questões elaboradas no MCTest e armazenadas em seu banco de dados. A filosofia do MCTest é trabalhar colaborativamente para produzir e utilizar material didático em avaliações. Dessa forma, as questões elaboradas por um professor em uma disciplina da UFABC estão disponíveis para os demais professores desta disciplina, para uso exclusivo em suas avaliações nesta universidade. 

Cada instituição pode definir seus próprios critérios de direito autoral para o conteúdo disponibilizado no banco de dados do MCTest. É importante ressaltar que o direito autoral do software apresentado na seção anterior não cobre essa parte. Portanto, cabe a cada instituição definir seus próprios critérios em suas implantações do MCTest.

A seguir, apresentamos o que foi definido para os professores da UFABC que optaram por utilizar o sistema, na implantação disponibilizada em \href{http://mctest.ufabc.edu.br/According}{mctest.ufabc.edu.br/According}:

\begin{mybox}{corCopia}{\textbf{De Acordo:\\\vspace{-3mm}\hrule\vspace{3mm}}}
O MCTest (disponível gratuitamente no \href{https://github.com/fzampirolli/mctest}{GitHub}) foi implantado no servidor da UFABC: \href{http://mctest.ufabc.edu.br}{mctest.ufabc.edu.br}.
\\\\
Na UFABC, o MCTest é um serviço colaborativo para geração e correção automática de atividades de formação (como Listas de Exercícios) e de avaliação (como Provas).
\\\\
Esse serviço está disponível gratuitamente para todos os docentes da UFABC.
\\\\
Para poder utilizar o MCTest, o professor deve inscrever-se na plataforma e ser cadastrado em alguma disciplina pelo seu coordenador.
\\\\
Todo o material intelectual (aulas, vídeos, questões, etc.) disponível neste site está protegido pelo direito autoral dos seus respectivos autores e, em última instância, é propriedade da UFABC. Os autores proprietários do material disponibilizado no site concordam em liberar o seu uso sem restrições pelos professores da instituição a qual está vinculado somente no âmbito das disciplinas e cursos desta instituição. Além disso, quando me inscrevo neste serviço, nesta instituição, CONCORDO que:
\begin{itemize}
    \item Posso utilizar livremente em meus exames todas as questões disponíveis já cadastradas na disciplina;
    \item Não posso publicar questões criadas por outros professores em quaisquer outras mídias, como, por exemplo, livros e artigos;
    \item Todas as novas questões que eu criar podem ser reaproveitadas em provas elaboradas por outros professores da mesma disciplina, sem prévio aviso;
    \item Só posso mudar as questões dos outros professores SOMENTE SE HOUVER ALGUM ERRO. Porém, sem alterar a autoria da questão.
\end{itemize}

\end{mybox}

\section{Organização do livro}

Este livro foi elaborado para fornecer um guia completo e abrangente sobre o MCTest, uma plataforma de avaliação e gerenciamento de aprendizado. O conteúdo está organizado em cinco partes, cada uma focada em um aspecto diferente do MCTest, desde os fundamentos até tópicos avançados e aplicações práticas, conforme apresentado na Figura \ref{fig:cap01_MCTest-book-v2} e resumido a seguir:

\begin{figure}[!ht]
  \centering
  \includegraphics[width=1.05\textwidth]{cap01_MCTest-book-v2.png}
  \caption{Organização do livro.}
  \label{fig:cap01_MCTest-book-v2}
\end{figure}

\begin{description}
    
\item[Parte \ref{part:fundamentos} -- Fundamentos do MCTest:] apresenta a introdução ao MCTest, seus componentes básicos e funcionalidades essenciais. Esta parte inclui o Capítulo \ref{ch:visaoGeral} -- \nameref{ch:visaoGeral} e o Capítulo \ref{ch:metodosBasicos} -- \nameref{ch:metodosBasicos}, que abordam a visão geral do sistema, navegação, usuários e os métodos básicos de operação (CRUD - \textit{Create, Read, Update, Delete}). As seções são dedicadas à manutenção de diferentes áreas do sistema por usuários, administradores, coordenadores e professores.

\item[Parte \ref{part:questoesMCTest} -- Questões no MCTest:] trata de diferentes tipos de questões disponíveis no MCTest, como questões estáticas e paramétricas. Os Capítulos \ref{ch:questoesClassicasMCTest}  -- \nameref{ch:questoesClassicasMCTest} e \ref{ch:questoesCodigoMCTest} -- \nameref{ch:questoesCodigoMCTest} discutem questões de múltipla escolha (QM), questões de texto (QT) e questões de texto com código.

\item[Parte \ref{part:exames} -- Exames no MCTest:] aborda o processo de criação e gerenciamento de exames no MCTest, com uma visão geral no Capítulo \ref{ch:exames} -- \nameref{ch:exames}. Os Capítulos \ref{ch:examesQR}  -- \nameref{ch:examesQR}, \ref{ch:examesQM_QT} -- \nameref{ch:examesQM_QT}, \ref{ch:examesQM_QT_Moodle} -- \nameref{ch:examesQM_QT_Moodle} e \ref{ch:examesQT_VPL} -- \nameref{ch:examesQT_VPL} exploram o quadro de respostas (QR) e a integração com questões de múltipla escolha (QM) e/ou questões de texto (QT), além da combinação do MCTest com Moodle e VPL para exames.

\item[Parte \ref{part:experimentos} -- Experimentos de Uso do MCTest:] apresenta \ estudos de caso \ e \ exemplos \ práticos do uso do MCTest em ambientes educacionais. Os Capítulos \ref{ch:experimentos_QR} -- \nameref{ch:experimentos_QR}, \ref{ch:experimentos_QR_QT} -- \nameref{ch:experimentos_QR_QT} e \ref{ch:experimentos_VPL} -- \nameref{ch:experimentos_VPL} apresentam diferentes cenários envolvendo o quadro de respostas (QR), questões de múltipla escolha (QM) e/ou questões de texto (QT) e a integração do MCTest com Moodle e VPL.

\item[Parte \ref{part:questoesMoodle} -- Questões no Moodle:] foca na integração entre o MCTest e o Moodle, uma plataforma popular de aprendizado a distância. Os Capítulos \ref{ch:questoesClassicasMoodle} -- \nameref{ch:questoesClassicasMoodle}, \ref{ch:questoesCodigoMoodle} -- \nameref{ch:questoesCodigoMoodle} e \ref{ch:questoesMCTestMoodleVPL} -- \nameref{ch:questoesMCTestMoodleVPL} exploram diferentes tipos de questões, como questões clássicas, questões de código (VPL) e a combinação de MCTest, Moodle e VPL.  O leitor pode também pular essa parte se não desejar utilizar o Moodle.

\item[Parte \ref{part:topicosAvancados} -- Tópicos Avançados:] aprofunda-se em aspectos técnicos do MCTest, como bibliotecas e instalações, arquitetura de software, banco de dados, visão computacional e segurança. Os Capítulos \ref{ch:bibliotecas} -- \nameref{ch:bibliotecas}, \ref{ch:arquitetura} -- \nameref{ch:arquitetura}, \ref{ch:bd}, \ref{ch:vc} -- \nameref{ch:vc} e \ref{ch:seguranca} -- \nameref{ch:seguranca} oferecem informações detalhadas sobre esses tópicos. O leitor pode pular essa parte se tiver como objetivo apenas utilizar o MCTest já implantado em sua instituição.

\end{description}

O livro é finalizado com o Capítulo \ref{ch:conclusao} -- \nameref{ch:conclusao}, que resume as principais ideias apresentadas ao longo do texto e oferece orientações para futuras pesquisas e desenvolvimentos do MCTest pela comunidade, visto que se trata de um sistema de código aberto. Esse capítulo é especialmente valioso para aqueles que desejam se aprofundar no tema e contribuir para o desenvolvimento contínuo do MCTest, seja por meio de pesquisas adicionais ou pela implementação de novas funcionalidades.
